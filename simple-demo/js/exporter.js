/**
 * Exporter Module for Mood Notetaker
 * Allows exporting the session data (emotions, transcript, summary) as a Markdown file
 */

class Exporter {
  constructor() {
    this.emotions = [];
    this.transcript = '';
    this.summary = '';
    this.candidateSummary = '';
    this.sessionTimestamp = new Date().toISOString();
  }

  /**
   * Log an emotion for the timeline
   * @param {string} emotion The detected emotion
   * @param {number} timestamp The time of detection
   */
  logEmotion(emotion, timestamp = Date.now()) {
    this.emotions.push({
      emotion,
      timestamp,
      relativeTime: ((timestamp - this.sessionStartTime) / 1000).toFixed(1) + 's'
    });
  }

  /**
   * Start a new session
   */
  startSession() {
    this.emotions = [];
    this.transcript = '';
    this.summary = '';
    this.candidateSummary = '';
    this.sessionStartTime = Date.now();
    this.sessionTimestamp = new Date().toLocaleString();
  }

  /**
   * Update the transcript
   * @param {string} text The latest transcript text
   */
  updateTranscript(text) {
    this.transcript = text;
  }

  /**
   * Update the summary
   * @param {string} text The latest summary text
   */
  updateSummary(text) {
    this.summary = text;
  }

  /**
   * Update the candidate summary for interview mode
   * @param {string} text The latest candidate summary
   */
  updateCandidateSummary(text) {
    this.candidateSummary = text;
  }

  /**
   * Generate a Markdown representation of the session
   * @returns {string} The Markdown content
   */
  generateMarkdown() {
    const emotionCounts = this.countEmotions();
    const dominantEmotion = this.getDominantEmotion(emotionCounts);
    
    let markdown = `# Mood Notetaker Session\n\n`;
    markdown += `*Session recorded: ${this.sessionTimestamp}*\n\n`;
    
    markdown += `## Summary\n\n${this.summary || '*No summary generated*'}\n\n`;
    
    // Add candidate summary section if available (for interview mode)
    if (this.candidateSummary) {
      markdown += `## Candidate Summary\n\n${this.candidateSummary}\n\n`;
    }
    
    markdown += `## Emotion Analysis\n\n`;
    markdown += `**Dominant Emotion:** ${dominantEmotion}\n\n`;
    
    markdown += `### Emotion Timeline\n\n`;
    if (this.emotions.length > 0) {
      markdown += `| Time | Emotion |\n|------|--------|\n`;
      this.emotions.forEach(e => {
        markdown += `| ${e.relativeTime} | ${e.emotion} |\n`;
      });
    } else {
      markdown += `*No emotions recorded*\n`;
    }
    
    markdown += `\n### Emotion Distribution\n\n`;
    for (const [emotion, count] of Object.entries(emotionCounts)) {
      const percentage = Math.round((count / this.emotions.length) * 100) || 0;
      const bar = '▓'.repeat(Math.ceil(percentage / 5));
      markdown += `${emotion}: ${bar} ${percentage}%\n`;
    }
    
    markdown += `\n## Full Transcript\n\n`;
    markdown += this.transcript || '*No transcript recorded*';
    
    markdown += `\n\n---\n\n*Generated by Mood Notetaker*`;
    
    return markdown;
  }

  /**
   * Count occurrences of each emotion
   * @returns {Object} Counts of each emotion
   */
  countEmotions() {
    const counts = {
      'happy': 0,
      'sad': 0,
      'angry': 0,
      'surprised': 0,
      'fearful': 0,
      'disgusted': 0,
      'neutral': 0
    };
    
    this.emotions.forEach(e => {
      if (counts[e.emotion.toLowerCase()] !== undefined) {
        counts[e.emotion.toLowerCase()]++;
      }
    });
    
    return counts;
  }

  /**
   * Get the dominant emotion from counts
   * @param {Object} counts Emotion counts
   * @returns {string} The dominant emotion
   */
  getDominantEmotion(counts) {
    if (this.emotions.length === 0) return 'None detected';
    
    let maxEmotion = 'neutral';
    let maxCount = 0;
    
    for (const [emotion, count] of Object.entries(counts)) {
      if (count > maxCount) {
        maxCount = count;
        maxEmotion = emotion;
      }
    }
    
    return maxEmotion.charAt(0).toUpperCase() + maxEmotion.slice(1);
  }

  /**
   * Export the session data as a Markdown file
   */
  async exportSession() {
    // Try multiple approaches to get the audio processor
    const audioProcessor = 
      // 1. Try the global instance
      window.audioProcessor || 
      // 2. Try to find it from the app's global state if exposed
      (window.appState && window.appState.audioProcessor) ||
      // 3. Try to access a named instance if exists
      window.mainAudioProcessor;
    
    console.log('Starting export session with audio processor:', audioProcessor);
    
    // Get the full transcript history if available
    let transcriptHistory = [];
    let fullTranscriptDirect = [];
    
    if (audioProcessor && typeof audioProcessor.getFullTranscript === 'function') {
      // Try to get transcript from the method
      transcriptHistory = audioProcessor.getFullTranscript();
      console.log('Retrieved full transcript with', transcriptHistory.length, 'entries');
    } else if (audioProcessor && Array.isArray(audioProcessor.fullTranscript)) {
      // Try to access the fullTranscript property directly
      fullTranscriptDirect = audioProcessor.fullTranscript;
      console.log('Accessed fullTranscript property directly with', fullTranscriptDirect.length, 'entries');
      transcriptHistory = fullTranscriptDirect;
    } else {
      console.warn('Could not access full transcript - audio processor:', audioProcessor, 
                  'has getFullTranscript:', audioProcessor ? typeof audioProcessor.getFullTranscript : 'N/A');
    }
    
    // Use transcript history or fall back to visible transcript
    const transcriptElement = document.getElementById('transcript');
    const visibleTranscriptText = transcriptElement.innerText;
    
    // Get the current summary and generate a comprehensive one if possible
    const summaryElement = document.getElementById('summary');
    let summaryText = summaryElement.innerText || 'No summary available';
    
    // Try to generate a comprehensive summary from the full transcript
    try {
      if (transcriptHistory && transcriptHistory.length > 0) {
        const newSummary = await this.generateComprehensiveSummary(transcriptHistory);
        if (newSummary && newSummary.length > 10) {
          summaryText = newSummary;
        }
      }
    } catch (error) {
      console.error('Error getting comprehensive summary:', error);
      // Keep using the existing summary from the UI
    }
    
    // Get any emotion data that might be stored
    const emotionData = window.emotionDetector && window.emotionDetector.emotionHistory ? 
                       window.emotionDetector.emotionHistory : this.emotions;
    
    // Generate markdown with all available data
    let markdown = `# Mood Notetaker Session Report\n\n`;
    markdown += `**Date:** ${new Date().toLocaleDateString()}\n`;
    markdown += `**Time:** ${new Date().toLocaleTimeString()}\n\n`;
    
    // Add summary section
    markdown += `## Session Summary\n\n${summaryText || 'No summary available'}\n\n`;
    
    // Add emotion analysis section if available
    markdown += `## Emotion Analysis\n\n`;
    if (emotionData && emotionData.length > 0) {
      const emotionCounts = this.countEmotions();
      const dominantEmotion = this.getDominantEmotion(emotionCounts);
      markdown += `**Dominant Emotion:** ${dominantEmotion}\n\n`;
      
      // Add emotion timeline or distribution if available
      markdown += `### Emotion Timeline\n\n`;
      if (emotionData.length > 0) {
        markdown += `| Time | Emotion |\n|------|--------|\n`;
        emotionData.forEach(e => {
          markdown += `| ${e.relativeTime} | ${e.emotion} |\n`;
        });
      } else {
        markdown += `*No emotions recorded*\n`;
      }
      
      markdown += `\n### Emotion Distribution\n\n`;
      for (const [emotion, count] of Object.entries(emotionCounts)) {
        const percentage = Math.round((count / emotionData.length) * 100) || 0;
        const bar = '▓'.repeat(Math.ceil(percentage / 5));
        markdown += `${emotion}: ${bar} ${percentage}%\n`;
      }
    } else {
      markdown += `No emotion data recorded for this session.\n\n`;
    }
    
    // Add full transcript section with timestamps and emotions if available
    markdown += `## Full Transcript\n\n`;
    if (transcriptHistory && transcriptHistory.length > 0) {
      transcriptHistory.forEach(entry => {
        const time = new Date(entry.timestamp).toLocaleTimeString();
        const emotion = entry.emotion || 'Neutral';
        markdown += `**[${time}]** ${entry.text} *(${emotion})*\n\n`;
      });
    } else {
      markdown += `${visibleTranscriptText || 'No transcript recorded'}\n\n`;
    }
    
    // Footer
    markdown += `---\n*Generated by Mood Notetaker - AI-powered emotion and speech analysis*`;
    
    // Create and download file
    const blob = new Blob([markdown], { type: 'text/markdown' });
    const url = URL.createObjectURL(blob);
    
    const a = document.createElement('a');
    a.href = url;
    a.download = `mood-notetaker-session-${new Date().toISOString().slice(0, 19).replace(/:/g, '-')}.md`;
    a.style.display = 'none';
    
    document.body.appendChild(a);
    a.click();
    
    setTimeout(() => {
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
    }, 100);
  }

  async generateComprehensiveSummary(transcript) {
    // Debug logs to see what's happening
    console.log('Transcript for summary generation:', transcript);
    console.log('Transcript length:', transcript ? transcript.length : 0);
    
    const summaryElement = document.getElementById('summary');
    const currentSummary = summaryElement.textContent || '';
    
    // If we don't have a full transcript, just return the current summary
    if (!transcript || transcript.length === 0) {
      console.log('No transcript available, using current summary');
      return currentSummary;
    }
    
    // Prepare transcript for summarization
    const transcriptText = transcript.map(entry => 
      `${entry.text}`
    ).join(' ');
    
    console.log('Full transcript text length:', transcriptText.length);
    console.log('First 100 chars of transcript:', transcriptText.substring(0, 100));
    
    // Don't proceed if transcript is too short
    if (transcriptText.length < 100) {
      console.log('Transcript too short, using current summary');
      return currentSummary;
    }
    
    try {
      // Call OpenAI API if available
      if (config.openaiApiKey) {
        console.log('Calling OpenAI API for comprehensive summary');
        
        const apiBody = {
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: 'You are a helpful assistant that summarizes transcripts concisely.' },
            { role: 'user', content: `Please provide a comprehensive summary of the following transcript, focusing on key topics, insights, and emotional patterns: ${transcriptText}` }
          ],
          max_tokens: 10000
        };
        
        console.log('API request body:', apiBody);
        
        const response = await fetch(config.openaiEndpoint || 'https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${config.openaiApiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(apiBody)
        });
        
        console.log('API response status:', response.status);
        
        if (response.ok) {
          const data = await response.json();
          console.log('API response data:', data);
          
          if (data.choices && data.choices.length > 0) {
            const newSummary = data.choices[0].message.content.trim();
            console.log('Generated new summary:', newSummary);
            return newSummary;
          } else {
            console.log('No choices in API response, using current summary');
          }
        } else {
          const errorText = await response.text();
          console.error('OpenAI API error:', response.status, errorText);
        }
      } else {
        console.log('No OpenAI API key available, using current summary');
      }
      
      // If API call fails or is not available, return current summary
      return currentSummary;
    } catch (error) {
      console.error('Error generating comprehensive summary:', error);
      return currentSummary;
    }
  }
}

// Export the Exporter class
window.Exporter = Exporter; 